import numpy as np
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV, train_test_split

from sklearn.externals import joblib  #用来保存模型

#此文件用来进行训练svm

def load_data(filename):

    data = np.genfromtxt(filename, delimiter=',',skip_header=1)
    x = data[1:, 1:49].astype(float)  
    y = data[1:, 49].astype(int)  
    #scaler = StandardScaler()   #sklearn 数据预处理的工具。
    #x_std = scaler.fit_transform(x)  # 标准化  
    # 将数据划分为训练集和测试集，test_size=.3表示30%的测试集
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2)
    return x_train, x_test, y_train, y_test

def svm_c(x_train, x_test, y_train, y_test):
     # rbf核函数，设置数据权重
     svc = SVC(kernel='rbf', class_weight='balanced',probability=True)
     c_range = np.logspace(-5, 15, 11, base=2)
     gamma_range = np.logspace(-9, 3, 13, base=2)
     # 网格搜索交叉验证的参数范围，cv=3,3折交叉
     param_grid = [{'kernel': ['rbf'], 'C': c_range, 'gamma': gamma_range}]
     grid = GridSearchCV(svc, param_grid, cv=3, n_jobs=-1)  #定义模型。
     # 训练模型

     x_train_1 = x_train[:,0:47]  
     x_test_1 = x_test[:,0:47]
     w_train = x_train[:,47]
     clf = grid.fit(x_train_1, y_train,w_train)
     # 计算测试集精度
     score = grid.score(x_test_1, y_test)
     print('精度为%s' % score)
     joblib.dump(grid, "model/svm_model_1.pkl")

if __name__ == '__main__':
     svm_c(*load_data('data_processed/data_svm1.csv'))  
